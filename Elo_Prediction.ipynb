{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14501a60",
   "metadata": {},
   "source": [
    "# Predicting Elo Scores Based on Player Performance through Board States"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a366de8",
   "metadata": {},
   "source": [
    "## Team Members\n",
    "### Alberto Garcia Roberto Palacios Logan Druley"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ed3e01",
   "metadata": {},
   "source": [
    "Elo rankings are scores assigned to chess players based on their performance against opponents. Elo scores are calculated by subtracting a player's expected score from their actual score and then multiplying that result by a factor K that controls how fast ratings in a given system are meant to change. The result of this calculation is then added to the player's rating. The formula for this calculation is:\n",
    "$$\n",
    "R_A' = R_A + K(S_A - E_A)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f6bddc",
   "metadata": {},
   "source": [
    "However, a player's Elo rating takes a signficant amount of time to reveal itself. A player must take part in several games before their performance reveals their current skill level. Our plan is to take annotated chess games with stated Elo rankings for each player and train a transformer to read the board states of games. Based on the moves a player takes in relation to their opponent we want the transformer predict the Elo ranking of said player. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02ee2267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.insert(0, os.getcwd())\n",
    "\n",
    "# Import functions from preprocess_data.py\n",
    "from scripts.preprocess_data import decompress_and_parse_pgn, create_datasets\n",
    "from src.data.parser import parse_pgn_stream, split_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d70e4b6",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cea2f05",
   "metadata": {},
   "source": [
    "Here we start by decompressing and then processing 90 Mb worth of annotated games to prepare them for model training. The games are parsed into relevant metadata including the white and black player's Elo rating and also transforms game turns into FEN strings. This transformation allows use to process the entire board's state which in turn gives us the opportunity to use self-attention to discover the importance of each move in the larger context of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90edbd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decompressing and parsing PGN file: lichess_db_standard_rated_2013-01.pgn.zst\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing | 100,000 games | 145 games/sec: : 100batch [11:30,  7.56s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: Saved 100,000 games to data/processed\\games_batch_100.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing | 121,114 games | 141 games/sec: : 122batch [14:20,  7.05s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Total games parsed: 121,114\n",
      "✓ Processing time: 861.1 seconds\n",
      "✓ Average speed: 141 games/second\n",
      "\n",
      "Saving all games...\n",
      "✓ Saved to data/processed\\all_games.pkl\n",
      "\n",
      "Splitting dataset into train/val/test...\n",
      "\n",
      "✓ Train: 96,891 games (80.0%)\n",
      "✓ Val:   12,111 games (10.0%)\n",
      "✓ Test:  12,112 games (10.0%)\n",
      "\n",
      "Saving dataset splits...\n",
      "✓ Saved to data/processed\\dataset_splits.pkl\n",
      "\n",
      "\n",
      "✓ Processing complete!\n",
      "  Total games: 121,114\n",
      "  Train: 96,891\n",
      "  Val: 12,111\n",
      "  Test: 12,112\n"
     ]
    }
   ],
   "source": [
    "# Process the Lichess PGN file\n",
    "input_file = \"lichess_db_standard_rated_2013-01.pgn.zst\"\n",
    "output_dir = \"data/processed\"\n",
    "\n",
    "# Decompress and parse the PGN file\n",
    "games = decompress_and_parse_pgn(\n",
    "    input_path=input_file,\n",
    "    output_dir=output_dir,\n",
    "    max_games=None,  # Process all games (set to a number like 10000 for testing)\n",
    "    batch_size=1000\n",
    ")\n",
    "\n",
    "# Create train/val/test splits\n",
    "train_games, val_games, test_games = create_datasets(\n",
    "    games=games,\n",
    "    output_dir=output_dir,\n",
    "    train_ratio=0.8,\n",
    "    val_ratio=0.1,\n",
    "    test_ratio=0.1\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Processing complete!\")\n",
    "print(f\"  Total games: {len(games):,}\")\n",
    "print(f\"  Train: {len(train_games):,}\")\n",
    "print(f\"  Val: {len(val_games):,}\")\n",
    "print(f\"  Test: {len(test_games):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d259b10",
   "metadata": {},
   "source": [
    "## Baseline Model: LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c34b0a",
   "metadata": {},
   "source": [
    "Once we've processed the data and then seperated it into train, validation, and test sets, we can then begin to train our initial baseline model. For this purpose, we've chosen an LSTM model as it has the capability to capture relationships across time. However, the performance of an LSTM should be weak in comparison to that of a Transformer with self-attention. As such, this baseline will tell us whether or not we have produce a model with any kind of significant ability to predict Elo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a26ca479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:scripts.train_model:Train: 5000, Val: 500, Test: 500\n",
      "INFO:scripts.train_model:Creating dataloaders...\n",
      "INFO:scripts.train_model:Creating lstm model...\n",
      "INFO:scripts.train_model:Saved config to experiments/quick_test\\config_20251208_224153.json\n",
      "INFO:scripts.train_model:Starting training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from previous cell...\n",
      "\n",
      "Full dataset: Train=96891, Val=12111, Test=12112\n",
      "Creating subset for quick test (5000 train, 500 val, 500 test)...\n",
      "Subset: Train=5000, Val=500, Test=500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 157/157 [09:13<00:00,  3.53s/it, loss=0.0106, mae=0.0816]\n",
      "Validating: 100%|██████████| 16/16 [00:19<00:00,  1.23s/it, loss=0.0101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Train MAE: 0.081552 | Val MAE: 0.081105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 157/157 [08:53<00:00,  3.40s/it, loss=0.0105, mae=0.0811]\n",
      "Validating: 100%|██████████| 16/16 [00:19<00:00,  1.23s/it, loss=0.00991]\n",
      "INFO:scripts.train_model:Evaluating on test set...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 | Train MAE: 0.081064 | Val MAE: 0.080164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 16/16 [00:20<00:00,  1.25s/it, loss=0.0111]\n",
      "INFO:scripts.train_model:Test MAE: 0.085656\n",
      "INFO:scripts.train_model:Test MAE (Elo): 171.30\n",
      "INFO:scripts.train_model:\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUICK TEST RESULTS\n",
      "============================================================\n",
      "Test MAE (normalized): 0.085656\n",
      "Test RMSE (normalized): 0.105208\n",
      "Test MAE (Elo points): 171.30\n",
      "Test RMSE (Elo points): 210.42\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Train LSTM model with subset of data\n",
    "from scripts.train_model import train_model, load_dataset\n",
    "import random\n",
    "\n",
    "# Check if train_games exists (from previous cell), otherwise load from disk\n",
    "if 'train_games' not in globals() or train_games is None:\n",
    "    print(\"Loading dataset from disk...\")\n",
    "    data_dir = \"data/processed\"\n",
    "    train_games, val_games, test_games = load_dataset(data_dir)\n",
    "    \n",
    "    if train_games is None:\n",
    "        raise ValueError(\"No data found! Please run the data processing cell (Cell 4) first.\")\n",
    "else:\n",
    "    print(\"Using data from previous cell...\")\n",
    "\n",
    "print(f\"\\nFull dataset: Train={len(train_games)}, Val={len(val_games)}, Test={len(test_games)}\")\n",
    "print(\"Creating subset for quick test (5000 train, 500 val, 500 test)...\")\n",
    "\n",
    "random.seed(42)\n",
    "train_games = random.sample(train_games, min(5000, len(train_games)))\n",
    "val_games = random.sample(val_games, min(500, len(val_games)))\n",
    "test_games = random.sample(test_games, min(500, len(test_games)))\n",
    "\n",
    "print(f\"Subset: Train={len(train_games)}, Val={len(val_games)}, Test={len(test_games)}\\n\")\n",
    "\n",
    "# Train the model with the subset\n",
    "trainer, history, test_metrics = train_model(\n",
    "    train_games=train_games,\n",
    "    val_games=val_games,\n",
    "    test_games=test_games,\n",
    "    model=\"lstm\",\n",
    "    batch_size=32,\n",
    "    epochs=2,  # Quick test: 2 epochs (~30 min)\n",
    "    lr=1e-3,\n",
    "    dropout=0.1,\n",
    "    embedding_dim=128,\n",
    "    seed=42,\n",
    "    output_dir=\"experiments/quick_test\",\n",
    "    early_stopping=False,\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"QUICK TEST RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Test MAE (normalized): {test_metrics['mae']:.6f}\")\n",
    "print(f\"Test RMSE (normalized): {test_metrics['rmse']:.6f}\")\n",
    "if 'mae_elo' in test_metrics:\n",
    "    print(f\"Test MAE (Elo points): {test_metrics['mae_elo']:.2f}\")\n",
    "    print(f\"Test RMSE (Elo points): {test_metrics['rmse_elo']:.2f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e10a880",
   "metadata": {},
   "source": [
    "This initial run only encompasses portion of our data and despite only runing for 2 epoch, we can already see that the LSTM model performs within the 100-250 Elo range that we were looking for as a baseline. The +0.02 gap between RMSE and MAE suggests there no large outliers in this sample of our data but that might change when working with a larger dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
